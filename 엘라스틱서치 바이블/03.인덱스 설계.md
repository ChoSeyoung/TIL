## 인덱스 설정
```
GET [인덱스 이름]/_settings
```
### number_of_shards
인덱스가 데이터를 몇개의 샤드로 처리할것인지 지정하는 값.
한번 지정하면 reindex 같은 동작을 통해 인덱스를 통째로 재색인하는 등 특별한 작업을 수행하지 않는 한 변경할 수 없다.
샤드 하나마다 루씬 인덱스가 하나씩 더 생성된다는 사실과 주 샤드 하나당 복제본 샤드도 늘어난다.
클러스터에 샤드 숫자가 너무 많아지면 클러스터 성능이 떨어지고, 특히 색인 성능이 감소한다.
클러스터에 샤드 숫자가 너무 적어지면 장애 상황에서 샤드 복구 상황에 너무 많은 시간이 소요되고 클러스터 안정성이 떨어진다.

### number_of_replicas
주 샤드 하나당 복제본 샤드를 몇 개 둘 것인지 지정하는 값.
샤드와는 다르게 동적으로 변경 가능하다.
```
PUT [인덱스 이름]/_settings
{
  "index.number_of_replicas": 0
}
```
값을 0 으로 지정하면 복제본 샤드를 생성하지 않고 주 샤드만 둔다. 
값을 0 으로 주는 설정은 주로 대용량의 초기 데이터를 마이그레이션하는 등의 시나리오에서 쓰기 성능을 일시적으로 끌어올리기 위해 사용한다.

### refresh_interval
엘라스틱서치가 해당 인덱스를 대상으로 refresh를 얼마나 자주 수행할것인지를 지정하는 값.
엘라스틱서치 인덱스에 색인된 문서는 refresh 되어야 검색 대상이 되기 때문에 중요한 설정임.
```
PUT [인덱스 이름]/_setttings
{
  "index.refresh_interval": "1s"
}
```
값을 "1s"로 지정하면 1초에 한번씩 refresh를 수행한다. 
값을 -1로 지정하면 주기적으로 refresh를 수행하지 않는다.
해당 값이 명시적으로 설정되어있지 않다면 1초마다 refresh 를 수행한다.

## 매핑과 필드타입
매핑은 문서가 인덱스에 어떻게 색인되고 저장되는지 정의하는 부분이다. 

인덱스에 문서가 색인될 때 기존에 매핑 정보를 가지고 있지 않던 새로운 필드가 들어오면 
엘라스틱서치는 자동으로 문서의 내용을 보고 적당한 필드 타입을 지정해서 매핑 정보를 생성한다.

중요한 것은 필드 타입을 포함한 매핑 설정 내 대부분의 내용은 한 번 지정되면 사실상 변경이 불가능하다는 점이다. 
따라서 서비스 운영 환경에서 대용량의 데이터를 처리해야 할 때는 기본적으로 명시적 으로 매핑을 지정해서 인덱스를 운영해야 한다.

### 명시적 매핑 처리
```
PUT [인덱스 이름] 
{ 
  "mappings": { 
    "properties": { 
      "createdDate": { "type": "date", "format": "strict_date_time || epoch_millis" }, 
      "keywordString": { "type": "keyword" }, 
      "textString": { "type": "text" }
    } 
  }
}
```

### 매핑 추가
```
PUT [인덱스 이름]/_mapping 
{ 
  "properties": { "longValue": { "type": "long" } } 
}
```

## 필드 타입
|분류|종류|비고|
|---|---|---|
|심플 타입| text, keyword, date, long, double, boolean, ip 등|text, keyword, date에 대해 자세하게 짚고넘어가야한다.|
|계층 구조를 지원하는 타입| object, nested 등|-|
|그 외 특수한 타입| geo_point, geo_shape 등|-|

### 심플타입
|종류|설명|비고|
|---|---|---|
|long|64비트 부호 있는 정수||
|integer|32비트 부호 있는 정수||
|short|16비트 부호 있는 정수||
|byte|8비트 부호 있는 정수||
|double|64비트 부동소수점||
|float|32비트 부동소수점||
|epoch_millis|ms단위 epoch 시간|
|epoch_second|s단위 epoch 시간

### object와 nested차이
Elasticsearch에서 "object"와 "nested" 타입은 JSON 구조를 색인하는 방법에 있어서 중요한 차이점을 가집니다.

**Object 타입**: 기본적으로, Elasticsearch는 JSON 객체를 'object' 데이터 타입으로 취급합니다. 이 타입에서는, 중첩된 필드들이 독립적인 레코드로 취급되지 않고 상위 문서의 일부로 색인됩니다. 이는 객체 내의 개별 필드들이 서로 연관되어 있지 않다는 것을 의미합니다. 예를 들어, 한 문서 안에 여러 주소가 있는 경우, 각 주소의 필드들 (예: 도시, 거리명)은 서로 독립적으로 색인되며, 복잡한 관계를 표현하는 데 한계가 있습니다.

**Nested 타입**: 'nested' 데이터 타입은 중첩된 JSON 객체를 별도의 독립된 문서로 취급하여 색인합니다. 이를 통해 복잡한 데이터 구조에서 각 중첩된 객체 내의 필드들 간의 관계를 유지할 수 있습니다. 예를 들어, 한 사람이 여러 주소를 가지고 있고, 각 주소 내의 필드들 (예: 도시, 거리명)이 서로 연관되어 있다면, 'nested' 타입을 사용하는 것이 적합합니다. 이를 통해 더 정교한 쿼리가 가능해지고, 객체 간의 복잡한 관계를 효과적으로 표현할 수 있습니다.

간단히 말해서, 'object' 타입은 중첩된 데이터 구조를 단순한 방식으로 취급하는 반면, 'nested' 타입은 이러한 구조를 더 정교하게 처리하여 중첩된 객체 간의 관계를 유지합니다. 이 두 타입의 선택은 데이터의 구조와 쿼리의 필요성에 따라 결정되어야 합니다.

### text와 keyword차이
Elasticsearch에서 `text`와 `keyword` 타입은 문자열 데이터를 다루는 방식에서 중요한 차이점을 가집니다.

 **Text 타입**: `text` 필드는 전문(full-text) 검색에 사용됩니다. 이 타입의 데이터는 분석되어 인덱스에 저장됩니다. 즉, 입력된 문자열이 토큰화되고, 필요에 따라 소문자화, 스톱워드 제거, 어근 추출(스테밍) 등의 과정을 거치게 됩니다. 이러한 처리를 통해 `text` 필드는 대량의 텍스트(예: 뉴스 기사, 책 내용 등) 내에서 키워드 검색이나 텍스트 분석에 적합합니다. 하지만, 토큰화 과정 때문에 정확한 텍스트 매칭이나 정렬에는 적합하지 않습니다.

 **Keyword 타입**: `keyword` 필드는 정확한 값의 매칭, 정렬, 집계에 사용됩니다. 이 타입의 데이터는 분석되지 않고, 입력된 문자열 그대로 인덱스에 저장됩니다. 따라서, `keyword` 필드는 필터링, 정렬, 집계(예: 카운팅, 버킷화)에 적합하며, 정확한 값의 매칭이 필요한 경우(예: 이메일 주소, 태그, 상태 코드 등)에 주로 사용됩니다.

요약하자면, `text` 타입은 전문 검색에 적합하고, `keyword` 타입은 정확한 값의 매칭과 데이터의 집계, 정렬에 적합합니다. 이들 타입의 선택은 데이터의 사용 목적과 필요한 쿼리 유형에 따라 달라집니다.
이 외에도 두 타입은 정렬과 집계, 스크립트 작업을 수행할 때 동작의 차이가 있다. 정렬과 집계, 스크립트 작업의 대상이 될 필드는 text 타입보다 keyword 타입을 쓰는 편이 낫다. keyword 타입은 기본적으로 doc_values 라는 캐시를 사용하고 text 타입은 fielddata 라는 캐시를 사용하기 때문이다.


### 애널라이저
Elasticsearch의 애널라이저(Analyzer)는 텍스트 데이터를 처리하고 검색할 수 있는 형태로 변환하는 역할을 합니다. 애널라이저는 크게 세 가지 주요 구성 요소로 이루어져 있습니다.

1. **Tokenizer**: 텍스트를 개별 토큰(일반적으로 단어)으로 분리합니다. 예를 들어, "The quick brown fox"라는 텍스트는 ["The", "quick", "brown", "fox"]와 같이 토큰화될 수 있습니다.

2. **Token Filters**: 토큰화된 토큰에 다양한 변형을 가합니다. 이 과정에서 토큰을 소문자로 변환하거나, 스톱워드(예: "the", "and")를 제거하거나, 어근 추출(Stemming)을 수행할 수 있습니다.

3. **Character Filters**: 입력 텍스트에 대한 전처리 단계로, 특정 문자를 다른 문자로 대체하거나 HTML 태그와 같은 불필요한 문자를 제거합니다.

Elasticsearch는 여러 내장 애널라이저를 제공합니다. 예를 들어, `standard` 애널라이저는 대부분의 언어에 적합한 기본적인 토큰화와 필터링을 수행하고, `simple` 애널라이저는 모든 텍스트를 소문자로 변환하며, `whitespace` 애널라이저는 공백을 기준으로 텍스트를 토큰화합니다. 또한, 사용자는 특정 요구 사항에 맞게 사용자 정의 애널라이저를 구성할 수도 있습니다.

이러한 애널라이저의 설정은 Elasticsearch의 인덱스 매핑(mapping) 단계에서 정의되며, 검색과 색인 생성 과정에서 중요한 역할을 합니다. 텍스트 데이터의 성격과 검색 요구 사항에 맞는 애널라이저를 선택하거나 정의하는 것은 검색의 정확도와 효율성을 크게 향상시킬 수 있습니다.

### 애널라이저 적용
특정 텍스트 필드에 `standard` 애널라이저를 적용하는 매핑은 다음과 같이 정의할 수 있습니다:

```json
PUT /my_index
{
  "mappings": {
    "properties": {
      "my_text_field": {
        "type": "text",
        "analyzer": "standard"
      }
    }
  }
}
```

이 예시에서 `my_text_field`는 `text` 타입으로 정의되었고, `standard` 애널라이저가 적용됩니다. 이렇게 설정하면, `my_text_field` 필드에 저장되는 데이터는 `standard` 애널라이저의 규칙에 따라 처리됩니다.

애널라이저의 적용은 검색 쿼리의 정확도와 성능에 큰 영향을 미칠 수 있으므로, 데이터의 성격과 검색 요구 사항을 고려하여 적절한 애널라이저를 선택하는 것이 중요합니다.








doc_values
fielddata
_source 
인덱스 코덱 변경
synthetic source
index속성
enabled 설정

